{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Label Transfer\n",
    "\n",
    "> The `KNN_Label_transfer` module provides functionality for label transfer between datasets using k-nearest neighbors (KNN) algorithms. It includes methods for majority and weighted voting based on nearest neighbors, calculation of centroids for labeled data, and label assignment based on nearest centroids. This module is designed to facilitate the propagation of labels from a reference dataset with known labels to a query dataset where labels are unknown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp transfer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will utilize FAISS to identify the nearest neighbor for each cell in the query dataset from the reference dataset. After identifying the nearest neighbor, we will assign the annotation of the cell in the query dataset to match the annotation of its nearest neighbor in the reference dataset. Thanks to Meta's optimization of FAISS, we can perform these nearest neighbor searches in batches and on the GPU, which significantly speeds up the process. The IndexFlatL2 function is used to calculate the L2 (or Euclidean) distance between all points in our query vector and the vectors in the reference index. A diagram illustrating this process is provided below. For more detailed information on vector searches and maximizing the use of FAISS, refer to the link provided (image credit also included).\n",
    "\n",
    " When the K value in our K-Nearest Neighbors (KNN) algorithm is set to more than one neighbor, we need a method to determine the final predicted label. This is essential for ensuring the accuracy and reliability of our classification tasks. Below, we will implement three methods for this purpose:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Voting Method\n",
    "\n",
    "The Majority Voting Method is a technique used to determine the final label for each data point in the query dataset. This is achieved by conducting a simple majority vote among the labels of the K nearest neighbors in the reference dataset. The process involves the following steps:\n",
    "\n",
    "1. **Neighbor Identification**: For every data point in the query dataset, the K nearest neighbors in the reference dataset are identified.\n",
    "2. **Vote Counting**: The labels of these K neighbors are tallied.\n",
    "3. **Label Assignment**: The label with the highest tally is assigned to the query data point.\n",
    "\n",
    "It is important to note that this method assumes that each of the K neighbors has equal significance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import List as List\n",
    "from collections import Counter\n",
    "\n",
    "def knn_majority_voting(indices: List[List[int]], # A list of lists, where each sublist contains the indices of the k-nearest neighbors in the reference dataset for a given query point.\n",
    "                        reference_labels: List[str] # A list of labels corresponding to the points in the reference dataset.\n",
    "                        ) -> List[str]: # A list of labels for each point in the query dataset, determined by majority voting.\n",
    "    \"\"\"\n",
    "    Assigns labels to query dataset points using majority voting from k-nearest neighbors.\n",
    "    \"\"\"\n",
    "    query_labels = []\n",
    "    for ind in indices:\n",
    "        neighbor_labels = [reference_labels[i] for i in ind]\n",
    "        label_counts = Counter(neighbor_labels)\n",
    "        most_common_label = label_counts.most_common(1)[0][0]\n",
    "        query_labels.append(most_common_label)\n",
    "    return query_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Voting Method\n",
    "  \n",
    "The Weighted Voting Method is a technique that considers both the labels and the distances of the K nearest neighbors from the reference dataset. This method is especially beneficial when the neighbors are at different distances from the query point. The process involves the following steps:\n",
    "  \n",
    "1. Neighbor and Distance Identification: For each query point, the K nearest neighbors and their distances from the query point are identified.\n",
    "2. Weighted Vote Calculation: Each neighbor is assigned a weight based on its distance (neighbors closer to the query point are given higher weight).\n",
    "3. Vote Aggregation: The weighted votes for each label are aggregated.\n",
    "4. Label Assignment: The label with the highest aggregated weight is assigned to the query point.\n",
    "  \n",
    "This method allows neighbors that are closer to the query point to have more influence, potentially leading to more accurate predictions, especially in scenarios where the nearest neighbors are not uniformly distributed around the query point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import List as List\n",
    "from typing import Dict as Dict\n",
    "from collections import Counter\n",
    "\n",
    "def knn_weighted_voting(indices: List, # A list of lists, where each sublist contains the indices of the k-nearest neighbors in the reference dataset for a given query point.\n",
    "                        distances: List, # A list of lists, where each sublist contains the distances of the k-nearest neighbors from a given query point.\n",
    "                        reference_labels: List # A list of labels corresponding to the points in the reference dataset.\n",
    "                        ) -> List[str]: # A list of labels for each point in the query dataset, determined by weighted voting.\n",
    "    \"\"\"\n",
    "    Assigns labels to query dataset points using weighted voting from k-nearest neighbors.\n",
    "    \"\"\"\n",
    "    query_labels = []\n",
    "    for ind, dist in zip(indices, distances):\n",
    "        weighted_votes: Dict[str, float] = {}\n",
    "        for i, d in zip(ind, dist):\n",
    "            label = reference_labels[i]\n",
    "            weight = 1 / (d + 1e-6)  # Adding a small constant to avoid division by zero\n",
    "            weighted_votes[label] = weighted_votes.get(label, 0) + weight\n",
    "        most_common_label = max(weighted_votes, key=weighted_votes.get)\n",
    "        query_labels.append(most_common_label)\n",
    "    return query_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centroid-Based Label Assignment\n",
    "  \n",
    "The Centroid-Based Label Assignment method assigns labels to data points in a query dataset based on their closeness to the centroids of different classes in a reference dataset. The centroids are the average position of all points within a specific class. Here's a detailed breakdown of the process:\n",
    "  \n",
    "1. **Centroid Calculation**: For each label in the reference dataset, compute the centroid. A centroid is the arithmetic mean position of all the points sharing the same label. This step involves adding up all data points of each label and dividing by the total number of points for that label.\n",
    "  \n",
    "2. **Label Assignment by Nearest Centroid**: For each point in the query dataset, identify its closest centroid. The closest centroid is the one with the least Euclidean distance from the query point. The label of this nearest centroid is then assigned to the query point.\n",
    "  \n",
    "This method operates under the assumption that data points of the same class are typically clustered together, with the centroid serving as the central point of these clusters. It is particularly useful in situations where data points of the same class form distinct, compact clusters. However, its performance may be suboptimal in scenarios where the class distribution is highly irregular or overlapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "def calculate_centroids(reference_data: List[List[float]], # A list of lists, where each sublist represents a data point in the reference dataset.\n",
    "                        reference_labels: List[str] # A list of labels corresponding to the points in the reference dataset.\n",
    "                        ) -> Dict[str, np.ndarray]: # Returns a dictionary where each key is a label and the corresponding value is the centroid of that label.\n",
    "    \"\"\"\n",
    "    Calculates the centroids for each label in the reference dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Initialize a dictionary to store the sum of data points for each label.\n",
    "    label_sums = defaultdict(lambda: np.zeros(len(reference_data[0])))\n",
    "    \n",
    "    # Count the number of occurrences of each label in the reference dataset.\n",
    "    label_counts = Counter(reference_labels)\n",
    "    \n",
    "    # For each data point and its corresponding label in the reference dataset,\n",
    "    # add the data point to the sum of data points for that label.\n",
    "    for data, label in zip(reference_data, reference_labels):\n",
    "        label_sums[label] += np.array(data)\n",
    "    \n",
    "    # Calculate the centroid for each label by dividing the sum of data points for that label by the count of that label.\n",
    "    centroids = {label: label_sums[label] / count for label, count in label_counts.items()}\n",
    "    \n",
    "    return centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def assign_labels_by_nearest_centroid(query_data: List[List[float]], # A list of lists, where each sublist represents a data point in the query dataset.\n",
    "                                      centroids: Dict[str, np.ndarray] # A dictionary where each key is a label and the corresponding value is the centroid of that label.\n",
    "                                      ) -> List[str]: # Returns a list of labels assigned to each point in the query dataset based on the nearest centroid.\n",
    "    \"\"\"\n",
    "    Assigns labels to each point in the query dataset based on the nearest centroid.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store the labels for the query data points.\n",
    "    query_labels = []\n",
    "    \n",
    "    # For each data point in the query dataset,\n",
    "    for data in query_data:\n",
    "        # Convert the data point to a numpy array.\n",
    "        data_point = np.array(data)\n",
    "        \n",
    "        # Find the label of the centroid closest to the data point.\n",
    "        # The closest centroid is the one with the least Euclidean distance from the data point.\n",
    "        closest_label = min(centroids.keys(), key=lambda label: np.linalg.norm(data_point - centroids[label]))\n",
    "        \n",
    "        # Append the label of the closest centroid to the list of labels for the query data points.\n",
    "        query_labels.append(closest_label)\n",
    "    \n",
    "    # Return the list of labels for the query data points.\n",
    "    return query_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Label Transfer\n",
    "The following section of code implements our label transfer algorithm using FAISS. This function is designed to produce a very simple label transfer under default conditions, i.e., when \\( k = 1 \\). In this case, there is no need for label consensus as there is only one nearest neighbor.\n",
    "\n",
    "However, the function also provides the flexibility to vary \\( k \\), the number of nearest neighbors considered for label assignment. When \\( k > 1 \\), a label consensus method is required to decide the label for the query point based on the labels of its \\( k \\) nearest neighbors. The function supports three label consensus methods: 'majority_voting', 'weighted_voting', and 'centroid_based'.\n",
    "\n",
    "'majority_voting' assigns the label that appears most frequently among the \\( k \\) nearest neighbors. In case of a tie, it selects the label of the closest neighbor among the tied labels.\n",
    "\n",
    "'weighted_voting' assigns the label based on a weighted vote where closer neighbors have a higher weight. The weight of each neighbor is inversely proportional to its distance from the query point.\n",
    "\n",
    "'centroid_based' assigns labels to data points in the query dataset based on their closeness to the centroids of different classes in the reference dataset. This method is particularly useful in situations where data points of the same class form distinct, compact clusters.\n",
    "\n",
    "The function also allows the distance metric to be varied according to any metric supported by FAISS. This provides additional flexibility in handling different types of data distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import List, Optional, Union, Tuple\n",
    "\n",
    "\n",
    "def labels(embedding_array_reference: np.ndarray, # A numpy array representing the reference dataset.\n",
    "                       embedding_array_query: np.ndarray, # A numpy array representing the query dataset.\n",
    "                       reference_labels: List[str], # A list of labels for the reference dataset.\n",
    "                       k: int = 1, # The number of nearest neighbors to consider for label assignment.\n",
    "                       use_gpu: bool = True, # Whether to use GPU for computation.\n",
    "                       batch_size: Optional[int] = None, # The size of the batch for computation. If None, the entire query dataset is processed in one batch.\n",
    "                       distance_metric: str = 'L2', # The distance metric to use. Can be 'L2' or 'IP'.\n",
    "                       label_consensus: str = 'majority_voting', # The label consensus method to use. Can be 'majority_voting', 'weighted_voting', or 'centroid_based'.\n",
    "                       timed: bool = False # Whether to return the time taken for label transfer.\n",
    "                       ) -> Union[List[str], Tuple[List[str], float]]: # Returns a list of labels for the query dataset. If timed is True, also returns the time taken for label transfer.\n",
    "    \n",
    "    \"Transfers labels from a reference dataset to a query dataset using FAISS.\"\n",
    "    \n",
    "    \n",
    "    from collections import Counter, defaultdict\n",
    "    import numpy as np\n",
    "    import faiss\n",
    "    import time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dimension = embedding_array_reference.shape[1]\n",
    "    res = faiss.StandardGpuResources() if use_gpu else None\n",
    "    if use_gpu:\n",
    "        res.noTempMemory()\n",
    "    if distance_metric == 'L2':\n",
    "        index = faiss.GpuIndexFlatL2(res, dimension) if use_gpu else faiss.IndexFlatL2(dimension)\n",
    "    elif distance_metric == 'IP':\n",
    "        index = faiss.GpuIndexFlatIP(res, dimension) if use_gpu else faiss.IndexFlatIP(dimension)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid distance metric. Choose 'L2' or 'IP'.\")\n",
    "    index.add(embedding_array_reference)\n",
    "    num_query_points = embedding_array_query.shape[0]\n",
    "    batch_size = batch_size or num_query_points\n",
    "    query_labels = []\n",
    "    for i in range(0, num_query_points, batch_size):\n",
    "        batch_query = embedding_array_query[i:i + batch_size]\n",
    "        distances, indices = index.search(batch_query, k)\n",
    "        if k > 1 and label_consensus == 'majority_voting':\n",
    "            batch_labels = knn_majority_voting(indices, reference_labels)\n",
    "        elif k > 1 and label_consensus == 'weighted_voting':\n",
    "            batch_labels = knn_weighted_voting(indices, distances, reference_labels)\n",
    "        elif label_consensus == 'centroid_based':\n",
    "            if i == 0:  # Calculate centroids only once\n",
    "                centroids = calculate_centroids(embedding_array_reference, reference_labels)\n",
    "            batch_labels = assign_labels_by_nearest_centroid(batch_query, centroids)\n",
    "        else:\n",
    "            batch_labels = [reference_labels[i[0]] for i in indices]\n",
    "        query_labels.extend(batch_labels)\n",
    "    end_time = time.time()\n",
    "    duration_minutes = (end_time - start_time) / 60\n",
    "    if timed:\n",
    "        return query_labels, duration_minutes\n",
    "    else:\n",
    "        return query_labels\n",
    "# End of Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
